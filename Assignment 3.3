Components of Hadoop 2.x:
 1.) HDFS NameNode (MASTER DAEMON -1 IN NUMBER) 
     * Contains the Hadoop FileSystem Tree and other metadata information about files and directories.
     * NameNode is the centerpiece of  HDFS.
     * NameNode is also known as the Master
     * NameNode only stores the metadata of HDFS â€“ the directory tree of all files in the file system, and tracks the files across the cluster.

     A NameNode contains two important files on its hard disk:
     1. fsimage (file system image) contains:
     * A directory structure of the HDFS
     * Replication level of the files
     2. Edits
     * When any operation takes place in HDFS, the directory structure gets modified
     * These modifications are stored in the memory as well as in the edits files (edits files are stored on the hard disk)
2.) HDFS Secondary NameNode 
     * Performs house-keeping activities for NameNodes, like the periodic merging of namespace and edits. 
     * This is not a back up for a NameNode.
 Working of Secondary NameNode:
     * It gets the edit logs from the namenode in regular intervals and applies to fsimage
     * Once it has new fsimage, it copies back to namenode
     * Namenode will use this fsimage for the next restart,which will reduce the startup time
3.) HDFS DataNode
     * DataNode is responsible for storing the actual data in HDFS.
     * DataNode is also known as the Slave
     * NameNode and DataNode are in constant communication.
     * When a DataNode is down, it does not affect the availability of data or the cluster. 
     * NameNode will arrange for replication for the blocks managed by the DataNode that is not available.
4.) MapReduce
      MapReduce is a processing technique and a program model for distributed computing based on java. The MapReduce algorithm contains two important tasks, namely Map and Reduce. 
      * Map takes a set of data and converts it into another set of data, where individual elements are broken down into tuples (key/value pairs). 
      * Reduce task, which takes the output from a map as an input and combines those data tuples into a smaller set of tuples
5.) YARN(Yet Another Resource Negotiator):
      * The YARN ResourceManager is responsible for tracking the resources in a cluster and scheduling applications 
      * The ResourceManager was a single point of failure in a YARN cluster. 
      * The ResourceManager high availability (HA) feature adds redundancy in the form of an active-standby ResourceManager pair to remove this single point of failure.      
      * The Resource Manager (one per cluster) is the master. It knows where the slaves are located (Rack Awareness) and how many resources they have. 
      * It runs several services, the most important is the Resource Scheduler which decides how to assign the resources.
6.) Node Manager:
      * the Node Manager (many per cluster) is the slave of the infrastructure. 
      * When it starts, it announces himself to the Resource Manager. Periodically, it sends an heartbeat to the Resource Manager. Each Node Manager offers some resources to the cluster. 
      * Its resource capacity is the amount of memory and the number of vcores. 
